Here's a simple explanation of how communication among simulators works in Simulus, especially when they‚Äôre part of a parallel/distributed simulation:
üß© Why Multiple Simulators?

Simulus allows you to run multiple simulators (think of them as isolated simulation environments), each modeling a different part of a larger system.

Example: Simulating a computer

    Simulator A: CPU core

    Simulator B: Memory

    Simulator C: Disk

    Simulator D: Network card

Each of these simulators may run on a different core, thread, or even machine, and they need to communicate to simulate real-world interaction.
üì¨ How Do Simulators Communicate?

They use Mailboxes.
üì® What is a Mailbox in Simulus?

    A mailbox is like a message drop-box.

    Messages can be:

        Sent with a delay (e.g., "arrive after 5 simulation units")

        Stored in a specific partition (like folders in a mailbox)

        Retrieved later by another process

Each simulator has named mailboxes that other simulators can send messages to.
üîó Cross-Simulator Messaging

    Simulator A can send a message to Simulator B‚Äôs mailbox, even if they‚Äôre running on different machines.

    Simulus handles the message transfer using pickle, which converts Python objects into a transmittable format (and back).

    The message must be pickle-able, meaning it should be a regular Python object (like numbers, strings, lists, etc.).

üì¶ Message Example

msg = {"data": "load finished", "time": sim.now}

This message can be sent from Simulator A to Simulator B using a mailbox.
‚è≥ Why Use Delays?

    In simulations, timing matters.

    If something takes 10 simulated units to reach another component, you use:

mailbox.send(partition=0, msg=msg, delay=10)

Then the message will arrive at the mailbox 10 units later in simulation time.
üîê Summary Table
Feature	Description
Mailbox	A communication channel between processes/simulators
Partition	Subdivision inside a mailbox (like folders for organizing msgs)
Delayed Send	Messages can be scheduled to arrive in the future (sim time)
Pickle Requirement	Messages must be Python-serializable
Cross-process / Cross-machine	Yes, works across processes and even distributed systems
‚úÖ Final Summary (In Plain Words)

Simulus lets multiple simulators model parts of a system. They send messages to each other through mailboxes, which can store any Python object (as long as it can be "pickled"). These messages can arrive after a simulated delay, helping synchronize events across the whole system ‚Äî even if simulators are running on different CPUs or machines.

Let me know if you'd like a visual diagram or example code of two simulators communicating.
------------------------------------
Here's a clear explanation of how parallel simulation on shared-memory multiprocessors works in Simulus, broken down into simple concepts:
üß† What is Parallel Simulation?

Instead of running one simulator (or simulation environment) sequentially on one CPU core, Simulus can run many simulators at the same time on multiple cores or CPUs ‚Äî this is called parallel simulation.
üíª What Are Shared-Memory Multiprocessors?

    Most modern computers (desktops, laptops, servers) have multiple CPU cores.

    These cores share access to the same memory, so they're called shared-memory multiprocessors.

    Example: A laptop with 2 cores and hyper-threading may appear to have 4 logical processors.

‚öôÔ∏è How Does Simulus Use This?
‚úÖ Step 1: Enable Parallel Execution

To run simulations in parallel, you set:

enable_smp=True

when creating a synchronized group of simulators.

This tells Simulus:
‚û°Ô∏è ‚ÄúUse all available cores to run each simulator in its own process.‚Äù
üß† What Happens Internally:

    Simulus forks new processes (like running separate Python programs).

    Each process runs one or more simulators, depending on how many simulators and processors you have.

üìä How Are Simulators Assigned?
Scenario	What Happens
More processors than simulators	Each simulator gets its own process on a separate processor
Fewer processors than simulators	Simulators are grouped and shared among available processors
Equal number of simulators and processors	Perfect 1:1 match ‚Äî maximum parallelism

Simulus uses a block decomposition strategy, meaning:

    Simulator 0‚Äì3 ‚Üí Processor 0

    Simulator 4‚Äì7 ‚Üí Processor 1

    etc.

üèì Example: Ping-Pong

    You can have 2 simulators ping-ponging messages.

    Run with enable_smp=True.

    Simulus assigns one simulator per core.

    Each prints its output separately (so output order might look "jumbled" in the terminal).

    But within each simulator, the printed events remain ordered.

üîÅ Example: Ring of 15 Simulators

    Each simulator receives a "hello" from its neighbor and passes it on.

    You can run this with:

sim.sync(enable_smp=True, smp_ways=4, show_runtime_report=True)

Simulus will:

    Evenly spread 15 simulators across the 4 cores.

    Group neighbors together when possible.

    At the end, print a performance report showing:

        Which simulator ran on which process

        How long each one took

üõ† Controlling Number of Cores (smp_ways)

You can override the default core usage like this:

sim.sync(enable_smp=True, smp_ways=2)

This tells Simulus to use only 2 processor cores, even if more are available.
üßæ Summary
Feature	Description
enable_smp=True	Enables parallel simulation
smp_ways	Limits number of processes used
Automatic assignment	Simulators are split across processes based on core availability
Output ordering	Output from different simulators may mix, but each simulator‚Äôs events stay ordered
Performance report	Shows how simulators were distributed and their execution stats
‚úÖ Why Use This?

    Speed: Handle large simulations faster by using all CPU cores.

    Scalability: Simulate complex systems like CPUs, networks, etc.

    Modularity: Split your simulation into components that run independently.

Let me know if you‚Äôd like an annotated example or visual diagram showing how this works!

----------------
üåç Why Use Distributed Simulation?

Running parallel simulations only on one computer has major limitations:
Limitation	Why it‚Äôs a problem
üî¢ Limited CPUs	You can‚Äôt use more than the number of cores your machine has (e.g., 4 or 8). So your speedup is limited.
üß† Limited Memory	One machine has limited RAM. Large simulations (e.g., entire datacenters or networks) need more memory than one machine can provide.
üîå Clusters are common	Many simulations today are run on clusters (lots of connected computers), not just one machine.

‚û°Ô∏è Distributed simulation solves these by spreading work across many machines.
üöÄ What Simulus Does

Simulus supports distributed simulation across many machines by using a technology called MPI ‚Äî the Message Passing Interface.
üîß What is MPI?

    MPI is a standard way for programs running on different computers (or cores) to send messages to each other.

    Used mostly in scientific computing.

    Think of it like a post office: your simulation can send timestamped messages between parts running on different machines.

üêç What is MPI4Py?

    MPI4Py is a Python wrapper around MPI.

    Simulus uses MPI4Py behind the scenes to do the communication.

‚úÖ Good news:
You don‚Äôt need to write MPI code ‚Äî Simulus handles it for you.
But you do need to install:

python -m pip install --user mpi4py

(MPI must be installed first, e.g., OpenMPI or MPICH)
üß† Parallel Model Used: SPMD

Simulus follows a programming model called SPMD (Single Program Multiple Data):
Concept	Meaning
Single Program	All machines run the same Python file
Multiple Data	Each machine (or core) handles different simulation components (e.g., one handles CPU, another handles memory, others handle I/O, etc.)
Each simulation instance (simulator):

    Runs as an MPI process

    Has a rank (e.g., 0, 1, 2, ‚Ä¶) ‚Äî like an ID

    Can have its own set of simulation tasks

    Can send messages to other ranks

üì® Communication Between Simulators

    Simulus uses mailboxes to send messages between simulators.

    Messages are:

        Timestamped

        Pickle-able Python objects (so they can be serialized between machines)

    This allows modeling true distributed systems, where different simulators act like separate devices (CPU, RAM, network interface, etc.).

üñ•Ô∏è Shared Memory + Distributed Combined

Simulus also allows hybrid setups:

    Distributed via MPI across machines

    Parallel via multi-core on each machine

So:

    Each machine runs multiple simulators

    Each simulator uses parallelism (via enable_smp=True)

    Simulators across machines communicate via MPI

üìå How to Use It in Code

To find out the rank of each simulator and how many are running:

from simulus import sync

rank = sync.comm_rank()
total = sync.comm_size()
print(f"I am simulator {rank} of {total}")

Each rank can do different simulation logic ‚Äî e.g., simulator 0 models the CPU, simulator 1 models RAM, etc.
üßæ Summary
Feature	Description
MPI	Technology used for inter-machine communication
MPI4Py	Python binding used by Simulus (you install it, Simulus uses it)
SPMD	All simulators run same code, handle different parts
Mailboxes	How Simulus sends timestamped messages between simulators
Hybrid Parallelism	Combine shared-memory and distributed memory execution
Want a visual diagram or full cluster example script next?
You said:
how do you define multiple machines ? like 2 computers in two different locations ?
ChatGPT said:

Great question. When we talk about "multiple machines" in the context of Simulus and distributed simulation using MPI, we mean two or more physically distinct computers (or servers) that are connected together via a network ‚Äî typically on the same local network or cluster, but technically it can be computers in different geographic locations too.
üîå How Are Multiple Machines Defined?
‚úÖ Basic Setup:

To define multiple machines for a distributed simulation:

    You have at least 2 computers (e.g., comp1 and comp2).

    These computers must:

        Have MPI installed (e.g., OpenMPI).

        Have Python + mpi4py + simulus installed.

        Be able to communicate over SSH (passwordless login is preferred for clusters).

        Access the same Python script, typically via:

            A shared file system (e.g., NFS), or

            Copying the script manually to each machine.

üåê Can the Machines Be in Different Locations?

Technically yes, but practically no unless you‚Äôre advanced:
Aspect	Explanation
üåé Remote computers	It‚Äôs possible to simulate between computers in different locations (e.g., one in LA, one in NYC), but:
üîê Requires secure networking	You'd need VPN or SSH tunnels and open MPI ports, which is complex and risky
üïí Latency is a problem	Real-time performance will degrade due to internet delays
üõ† Clusters are preferred	In practice, simulations are run on HPC clusters or LAN-connected nodes
üõ†Ô∏è Example: Run Simulus on Two Machines
Suppose:

    comp1 has IP 192.168.1.10

    comp2 has IP 192.168.1.11

    Install OpenMPI and mpi4py on both:

sudo apt install openmpi-bin
pip install mpi4py simulus

Create a hostfile:

comp1 slots=2
comp2 slots=2

Run from one of the machines:

    mpirun -np 4 --hostfile my_hosts.txt python your_sim.py

This will launch 4 MPI processes, 2 on each machine.
üì¶ Recap
Concept	Means
Machine	A physical or virtual computer
Multiple Machines	Two or more computers on a network
Defined via	MPI hostfile or MPI launch config
Location	Same LAN or secure VPN cluster preferred
Connection	SSH and open network ports
Execution	mpirun or mpiexec launches the script across all machines
